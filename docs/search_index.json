[
["index.html", "Data Analysis in Social Science 3 1 Introduction 1.1 Things to do before the next class", " Data Analysis in Social Science 3 Alexey Bessudnov 2018-03-31 1 Introduction This is a website for the Data Analysis in Social Science 3 module at the University of Exeter (SOC2094/3094 POL2094/3094) as offered in Term 2 in 2018. The website will be updated with new R Markdown scripts as the course progresses. All the scripts are provided on the ‘as is’ basis. The idea for this module is to teach you how to work with complex longitudinal data sets using data from the Understanding Society, a longitudinal household survey conducted in the UK. You will learn how to read complex data into R, manipulate and summarise data using dplyr, merge and restructure data frames, visualise data using ggplot2, create statistical reports with R Markdown and (possibly) interactive applications with Shiny. For more details see the module outline. The module is organised according to the “flipped classroom” pedagogy. This means that you read new material and do exercises before the class, and in class we work together on the exercises and discuss how what you learned at home can be applied to the Understanding Society data. The readings and exercises mostly come from the R for Data Science book by G.Grolemund and H.Wickham. The pre-requisites for this module are SOC/POL1041 and SOC/POL2077. All the scripts and other materials are available in the Github repository for the module: https://github.com/abessudnov/dataanalysis3 1.1 Things to do before the next class Before coming to class 2 please do the following: Register an account with the UK Data Service, create a data usage (or join the existing data usage that I have created) and download the Understanding Society data in the tab delimited format (SN6614). Read the User Manual and familiarise yourself with the structure of the data. Install Git and register an account on Github (if you do not have it already). Then you can either create a new repository for this module or fork my repository (see the link above). Create a project in R Studio for this repository. To learn how Git and Github work take this free online course: https://www.datacamp.com/courses/introduction-to-git-for-data-science/ In the root folder for your project create a folder “data” and put there the Understanding Society data as you downloaded them. The next subfolder must be “UKDA-6614-tab”. Never change anything in this folder. Also create an empty “myData” folder in the root folder. You do not want to track these two folders on Github. To avoid this, include the following two lines in your .gitignore file: data/ myData/ Read ch.11 (Data Import) from R for Data Science and do the exercises - http://r4ds.had.co.nz/data-import.html "],
["module-outline.html", "2 Module outline 2.1 Practical arrangements 2.2 Aims of the module 2.3 Attendance 2.4 Assessment 2.5 Syllabus plan 2.6 Reading list", " 2 Module outline 2.1 Practical arrangements Classes: Monday, 11.30am - 1.30pm, WSL 220 Classes begin on 15 January and end on 26 March. The class on 22 January (week 2) has been cancelled and moved to Friday 2 February, 10.30 - 12.30, WSL 220. Office hours (Amory A341) Monday, 2-3pm Friday, 12-1pm Email: A.Bessudnov [at] exeter.ac.uk 2.2 Aims of the module This is a fourth module in the data analysis in the social sciences series. In the Introduction to Social Data you learned the basics of descriptive statistics and R. Data Analysis 1 introduced you to statistical inference. Data Analysis 2 covered linear regression analysis. In Data Analysis 3 we are not going to learn new statistical techniques, but will focus on how to apply the techniques you already know to the analysis of real-life data sets and how to produce statistical reports. This is a skill that you may need in a variety of jobs where data analytic expertise is required, such as marketing analysis, policy analysis in various fields, web analytics, data journalism, academic research, etc. You already know how to use R to describe data and run simple statistical models. However, real-life data rarely come in the form of a perfectly formatted csv file ready for the analysis. The real life data sets often need to be reshaped, merged, recoded, aggregated and modified in various ways before you can even start your analysis. Unless you know how to do this you will not be able to produce good statistical reports. This year in this module we will use data from the Understanding Society, a large household panel study conducted in the UK. In the Immigration module we already used the cross-sectional Understanding Society data. In this module we will work with the longitudinal data, which introduces a number of technical challenges. Throughout the module we will use R for statistical analysis. You are expected to know the basics of data analysis in R. The only way to learn data analysis is to do data analysis. I will not be able to teach you this, but I can guide your independent learning. This year we will try the “flipped classroom” model of teaching. This means that you will be expected to read and master the required material BEFORE the class and we will use the time in class to answer additional questions and check your solutions rather than introduce new material. The pre-requisites for this module are POL/SOC1041 and POL/SOC2077. 2.3 Attendance This module is quite technical. As with other technical skills, missing some initial bits means that you may not be able to catch up. Attendance in this module is crucial. If you do not attend you will not be able to do well in this module. Even skipping a couple of classes will have negative consequences for your understanding of the material. Another negative consequence will be that you will slow the rest of the class down as I will have to explain the same things several times. If you plan not to attend classes please do not take this optional module. 2.4 Assessment The assessment for this module is a report of 3,500 words (in addition to figures and tables) with the results of statistical analysis you will undertake. This will be 100% of your final mark for this module. You will be given questions for the reports later in the module. In your analysis you will use the Understanding Society data. The deadline for submitting your reports through eBart is 29 March at 2pm. You will receive your marks and feedback by 5 May. Late submissions up to two weeks after the deadline will be capped at 40%. Submissions that are late for more than two weeks will not be accepted. 2.5 Syllabus plan I may change some topics as we proceed. Data structures in R Manipulating data with dplyr Longitudinal data in R. Wide and long formats. Reshaping Data visualisation with ggplot2 Producing statistical reports with R Markdown Interactive applications with Shiny Loops and other control structures. The apply family of functions Writing functions in R 2.6 Reading list The main text for this module: G.Grolemund &amp; H.Wickham. (2016). R for Data Science. Freely available at http://r4ds.had.co.nz/ In addition to this you can the following sources (among many others books on R). H.Wickham. (2015). ggplot2. Elegant Graphics for Data Analysis. 2nd ed. Springer. W.Chang. (2013). R Graphics Cookbook. O’Reilly. P.Spector. (2008). Data Manipulation with R. Springer. N.Matloff. (2011). The Art of R Programming. No Starch Press. H.Wickham. (2014). Advanced R. Chapman &amp; Hall. "],
["assignment.html", "3 Assignment", " 3 Assignment Your assignment for this module is to choose a topic, conduct an independent statistical analysis with the Understanding Society data and write up your results in a report that is about 3,500 words long. I wanted to give you as much flexibility as possible in preparing the report. I will not provide a detailed guidance on what you should analyse and how you should this. As this is an advanced module I expect you to be able to formulate a research question, identify the data you need and conduct the analysis independently. In other words, the idea is to throw you into the sea of data and find out if you can come up with a nice statistical report that answers a well defined question. However, there are a few rules. You must use the Understanding Society data and I suggest you use data from the indresp files (these are individual adult questionnaires). You must use longitudinal data, i.e. data from more than one wave and preferrably all seven waves of the Understanding Society. This will depend on your question though. If you only have data at two time points available and produce good analysis this is totally fine. But if you have data in all seven waves and only use two this is not fine. Generally you would select one time-varying variable and explore changes over time, in the whole sample and different population subgroups. For example, you may explore how people’s incomes changed from 2008 to 2016. You may want to conduct your analysis by gender, age group, location, etc. Other possible variables: Health Employment and job mobility State benefits Any other topic that you find interesting and that has longitudinal data available in the Understanding Society. You cannot use data on political interest and political preferences as we will explore these data in class. You must prepare your report in R Markdown. Submit the pdf file (with all the R syntax visible) through eBart. You do no need to submit your work on Github. Please keep your R syntax clear and provide commentary explaining to me what you do. The deadline for your reports is 3 May at 2pm. I suggest the following steps for your reports. First you need to find a topic that interests you and that has longitudinal data available. Check the User Manual, the questionnaires and data dictionaries for individual waves. Note that the Understanding Society has some modules that are present in each wave and some rotating modules that are only present in one or several waves. Once you have found a variable that interests you make sure that it is present in the data at least at two or more time points. Next you need to read the data into R. Start simple and only read in the data for your outcome variable and maybe sex and age. You will be able to add more variables later as long as you keep your syntax. Clean the data and look at the distributions. Think about the best way to describe and visualise your data. Do you see any interesting patterns and trends? At this stage you should start thinking about the story you want to tell us with your analysis. I do not expect you to do anything fancy statistically. Just providing descriptive statistics and visualisations is fine, as long as I can see that you have thought carefully about which statistics and graphs are best to answer your questions. Every table and chart you have in your report must contribute something to your story. That said, if you want to use some statistical modelling in your report (for example, linear regression) and you do this correctly this will be appreciated and I will give you extra marks for doing this. Once you have a feeling about the general direction of your analysis start adding the details. Maybe you want to explore some more variables; then you need to add them to the data set. For example, for the analysis of political interest I would start with looking at descriptive statistics for political interest for each wave and establish if it was stable or increased/decreased. Then I would think about how I can visualise the results. Then I may start adding details. Was the trend the same for men and women? Different age groups? Different parts of the country? Then if I want to do something fancy I would remember that in 2010 the UK had a general election. Can we get the date of the interview from the data and explore how political interest changed monthly in 2010? And then if I really want to do something very fancy I would read about applyng models with fixed effects to longitudinal data, talk to Alexey in his office hours and explore if change in people’s income over time is associated with the change in political interest. (The latter part is optional.) Write up the results. Start with a brief introduction. For political interest that would be approximately the following: Why are we interested in political interest? What happened in British politics between 2008 and 2016 that could affect the level of political interest? Maybe you can find and cite two or three papers that have already explored this topic. Then present your research questions. What are you aiming to achieve with your report? What questions will you answer? Briefly describe the data (variables you are going to use, what waves they are coming from, etc.). Present your statistical results. The structure of this part will depend on your results. This should not be just a collection of tables and graphs. Explain what you see in all those tables and graphs and why you have included them. Discussion. This is a very important part. You need to discuss here how the statistical results you have got contribute to our understanding of your topic (for example, political interest in Britain). Explain in substantive terms your results and discuss them. Why has political interest increased (or decresed, or ramained stable)? What factors contributed to this? The length of the report is 3,500 words, but I am not going to count your words and writing slightly more or slightly less is fine. Do not submit 100 pages. In the same way, if your report is obviously too short this is going to affect your mark. "],
["readdata.html", "4 Read data 4.1 Base R 4.2 Package readr 4.3 Package data.table 4.4 Other data formats 4.5 Saving the R workspace", " 4 Read data Please read ch.11 (Data import) from R for Data Science - http://r4ds.had.co.nz/data-import.html For this module we will use data from the Understanding Society survey (https://discover.ukdataservice.ac.uk/catalogue/?sn=6614). I assume that you have famliarised yourself with the data set, registered an account with the UK Data Service website and downloaded the data in the tab format. The first thing we need to do is to read the data in R. There are multiple ways of doing this. For all the examples I will use the individual adult data from wave 1 (a_indresp.tab). 4.1 Base R In base R we have the read.table function. I will wrap it into the system.time function to measure how long the execution will take. system.time(UndSoc1 &lt;- read.table(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;, header = TRUE, stringsAsFactors = FALSE)) ## user system elapsed ## 40.438 1.059 41.527 I set header = TRUE to make sure that the first row in the data is interpreted as variable names. stringsAsFacrors = FALSE means that the text variables will be read in as character vectors rather than factors. We can convert them into factors when necessary. 4.2 Package readr We can also read in these data with the package readr (part of tidyverse). The main advantage is that it works faster. library(readr) system.time(UndSoc2 &lt;- read_tsv(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;)) ## user system elapsed ## 9.829 0.481 10.319 readr was able to read the data set much faster than base R. 4.3 Package data.table The fread function from the data.table package is probably the fastest way to read in the data. library(data.table) system.time(UndSoc3 &lt;- fread(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;)) ## Read 78.4% of 50994 rows Read 50994 rows and 1364 (of 1364) columns from 0.187 GB file in 00:00:03 ## user system elapsed ## 2.402 0.210 2.615 It took less than 3 seconds! With small data sets the choice between these three methods is not very important, but with larger data the gain in efficiency that readr and data.table provide can be quite substantial. 4.4 Other data formats In R you can easily read in data in other formats, such as csv files, Stata, SPSS, SAS, Excel and others. There are many tutorials on how to do this on the web. See, for example, https://www.datacamp.com/courses/importing-data-in-r-part-1/ and https://www.datacamp.com/courses/importing-data-in-r-part-2 . 4.5 Saving the R workspace Once you have read your data into R you can save it as R workspace. # I will remove some objects from memory to speed things up rm(UndSoc2, UndSoc3) # saving R workspavce now in myData (you need to create myData first) save.image(&quot;myData/readTest.RData&quot;) Next time I need this file I can simply load the workspace. # first let&#39;s remove everything from the workspace rm(list = ls()) # load the workspace system.time(load(&quot;myData/readTest.RData&quot;)) ## user system elapsed ## 1.416 0.110 1.527 Of course, in R workspace you can save not only data frames but any objects: models, plots, functions, etc. "],
["transformdata.html", "5 Transform data 5.1 The pipe operator (%&gt;%) 5.2 Select variables 5.3 Select cases 5.4 Create new variables 5.5 Sort data 5.6 Summarise data", " 5 Transform data Please read ch.5 (Data transformation) from R for Data Science - http://r4ds.had.co.nz/transform.html Once you have imported your data in R you will usually want to clean it, transform it and produce some data summaries. All these tasks can be accomplished with base R. However, it is usually more convenient to use specialised packages for this, such as dplyr and data.table. In this module we will use dplyr. Let us read the data from wave 1 of the Understanding Society. library(tidyverse) W1 &lt;- read_tsv(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;) 5.1 The pipe operator (%&gt;%) Let us start with tabulating a variable for political interest. table(W1$a_vote6) ## ## -9 -7 -2 -1 1 2 3 4 ## 118 3262 42 42 4882 15862 14017 12769 Now if we want to convert this table into a table of proportions we need to do the following. prop.table(table(W1$a_vote6)) ## ## -9 -7 -2 -1 1 ## 0.0023139977 0.0639683100 0.0008236263 0.0008236263 0.0957367533 ## 2 3 4 ## 0.3110562027 0.2748754755 0.2504020081 Imagine now that you want to use the kable() function from the knitr package to print this table. We will need to convert the table into a data frame first and then apply the function kable. library(knitr) kable(data.frame(prop.table(table(W1$a_vote6))), digits = 2) Var1 Freq -9 0.00 -7 0.06 -2 0.00 -1 0.00 1 0.10 2 0.31 3 0.27 4 0.25 At this point we have four nested functions and the code becomes difficult to read. With the pipe operator (%&gt;%) you can achieve the same result with the following code. W1$a_vote6 %&gt;% table() %&gt;% prop.table() %&gt;% data.frame() %&gt;% kable(digits = 2) . Freq -9 0.00 -7 0.06 -2 0.00 -1 0.00 1 0.10 2 0.31 3 0.27 4 0.25 The pipe operator passes the results of the execution of a function to the next function. This makes code easier to write, read and understand. 5.2 Select variables Imagine we want to select some variables from a data frame. Indeed, W1 is too large for our purposes and we do not need all the variables today. Let us select the variables for sex, age, place of birth and measures of weight and height. In base R you could do the following: newW1 &lt;- subset(W1, select = c(&quot;pidp&quot;, &quot;a_sex&quot;, &quot;a_dvage&quot;, &quot;a_ukborn&quot;, &quot;a_hlht&quot;, &quot;a_hlhtf&quot;, &quot;a_hlhti&quot;, &quot;a_hlhtc&quot;, &quot;a_hlwt&quot;, &quot;a_hlwts&quot;, &quot;a_hlwtp&quot;, &quot;a_hlwtk&quot;)) head(newW1, 3) ## # A tibble: 3 x 12 ## pidp a_sex a_dvage a_ukborn a_hlht a_hlhtf a_hlhti a_hlhtc a_hlwt ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68001367 1 39 1 1 6 0 -8 1 ## 2 68004087 1 59 5 1 5 11 -8 2 ## 3 68006127 2 39 1 1 5 1 -8 1 ## # ... with 3 more variables: a_hlwts &lt;int&gt;, a_hlwtp &lt;int&gt;, a_hlwtk &lt;int&gt; With dplyr the following code will produce the same result. newW1 &lt;- W1 %&gt;% select(pidp:a_dvage, a_ukborn, a_hlht:a_hlwtk) head(newW1, 3) ## # A tibble: 3 x 12 ## pidp a_sex a_dvage a_ukborn a_hlht a_hlhtf a_hlhti a_hlhtc a_hlwt ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68001367 1 39 1 1 6 0 -8 1 ## 2 68004087 1 59 5 1 5 11 -8 2 ## 3 68006127 2 39 1 1 5 1 -8 1 ## # ... with 3 more variables: a_hlwts &lt;int&gt;, a_hlwtp &lt;int&gt;, a_hlwtk &lt;int&gt; Note that I combined together the variables that follow each other in the original data frame with :. 5.3 Select cases Another common task is to select cases based on some conditions. For example, we may want to have a data frame that only indludes women aged 18 to 25. In base R you can do the following. women &lt;- newW1[newW1$a_sex == 2 &amp; (newW1$a_dvage &gt;= 18 &amp; newW1$a_dvage &lt;=25),] In dplyr the code will be the following: newW1 %&gt;% filter(a_sex == 2 &amp; (a_dvage &gt;= 18 &amp; a_dvage &lt;=25)) %&gt;% head(3) ## # A tibble: 3 x 12 ## pidp a_sex a_dvage a_ukborn a_hlht a_hlhtf a_hlhti a_hlhtc a_hlwt ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68010207 2 24 1 1 5 5 -8 1 ## 2 68010891 2 23 1 -7 -7 -7 -7 -7 ## 3 68023131 2 23 1 1 5 9 -8 1 ## # ... with 3 more variables: a_hlwts &lt;int&gt;, a_hlwtp &lt;int&gt;, a_hlwtk &lt;int&gt; I am not saving the new data frame as an object here and just print the first three rows from the data to demonstrate the result. Imagine now you want to select only people born in Wales or Northern Ireland and aged over 40. newW1 %&gt;% filter((a_ukborn == 3 | a_ukborn == 4) &amp; a_dvage &gt; 40) %&gt;% head(3) ## # A tibble: 3 x 12 ## pidp a_sex a_dvage a_ukborn a_hlht a_hlhtf a_hlhti a_hlhtc a_hlwt ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68051011 2 41 3 1 5 5 -8 1 ## 2 68062567 2 50 4 1 5 1 -8 1 ## 3 68189727 2 95 3 1 5 4 -8 1 ## # ... with 3 more variables: a_hlwts &lt;int&gt;, a_hlwtp &lt;int&gt;, a_hlwtk &lt;int&gt; 5.4 Create new variables Let us create a new dummy variable scotland that takes the value of 1 if a person was born in Scotland and 0 otherwise. I will not show you how to do this in base R (I assume you know this already) and will focus on dplyr. newW1 %&gt;% mutate(scotland = ifelse(a_ukborn == 2, 1, 0)) %&gt;% head(3) ## # A tibble: 3 x 13 ## pidp a_sex a_dvage a_ukborn a_hlht a_hlhtf a_hlhti a_hlhtc a_hlwt ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68001367 1 39 1 1 6 0 -8 1 ## 2 68004087 1 59 5 1 5 11 -8 2 ## 3 68006127 2 39 1 1 5 1 -8 1 ## # ... with 4 more variables: a_hlwts &lt;int&gt;, a_hlwtp &lt;int&gt;, a_hlwtk &lt;int&gt;, ## # scotland &lt;dbl&gt; Here I use the function ifelse that evaluates a condition that a_ukborn == 2 and returns 1 if this is true and 0 if this is false. Now let us imagine we want to code a variable for the place of birth converting numeric values into text and coding missing values as NA. newW1 %&gt;% mutate(placeBirth = recode(a_ukborn, &quot;1&quot; = &quot;England&quot;, &quot;2&quot; = &quot;Scotland&quot;, &quot;3&quot; = &quot;Wales&quot;, &quot;4&quot; = &quot;Northern Ireland&quot;, &quot;5&quot; = &quot;not UK&quot;, .default = NA_character_)) %&gt;% head(3) ## # A tibble: 3 x 13 ## pidp a_sex a_dvage a_ukborn a_hlht a_hlhtf a_hlhti a_hlhtc a_hlwt ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68001367 1 39 1 1 6 0 -8 1 ## 2 68004087 1 59 5 1 5 11 -8 2 ## 3 68006127 2 39 1 1 5 1 -8 1 ## # ... with 4 more variables: a_hlwts &lt;int&gt;, a_hlwtp &lt;int&gt;, a_hlwtk &lt;int&gt;, ## # placeBirth &lt;chr&gt; .default = NA_character_ codes all the values that were not specifically matched (all negative values in our case) to missing values. We can compare the distributions of the original and recoded variables to make sure that everything is correct. newW1 %&gt;% mutate(placeBirth = recode(a_ukborn, &quot;1&quot; = &quot;England&quot;, &quot;2&quot; = &quot;Scotland&quot;, &quot;3&quot; = &quot;Wales&quot;, &quot;4&quot; = &quot;Northern Ireland&quot;, &quot;5&quot; = &quot;not UK&quot;, .default = NA_character_)) %&gt;% count(a_ukborn, placeBirth) ## # A tibble: 8 x 3 ## a_ukborn placeBirth n ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 -9 &lt;NA&gt; 6 ## 2 -2 &lt;NA&gt; 2 ## 3 -1 &lt;NA&gt; 8 ## 4 1 England 33480 ## 5 2 Scotland 3567 ## 6 3 Wales 2154 ## 7 4 Northern Ireland 2033 ## 8 5 not UK 9744 Now let us have a slightly more complicated case. We may want to code a variable for the body mass index (BMI) which is defined as weight in kilograms divided by the square of height in meters: \\[BMI = \\frac{weight_{kg}}{{height_{m}}^2}\\] The problem is that in our data set some people gave their weight in kilograms (a_hlwtk) and some in stones and pounds (a_hlwts and a_hlwtp). Similarly, some people gave their height in centimeters (a_hlhtc) and others in feet and inches (a_hlhtf and a_hlhti). We need to start with converting the measures for everyone to kilograms and centimeters and then we will be able to create a variable for BMI. These are the formulas for conversion: 1 feet = 30.48cm 1 inch = 2.54cm 1 stone = 6.35kg 1 pound = 0.45kg W1mod &lt;- newW1 %&gt;% # create a variable for height in cm # if height is measured in feet and inches (a_hlht == 1) and is not missing (a_hlhtf &gt; 0), # convert it to centimeters # otherwise if it is already measured in cm (a_hlht == 2) leave as it is # if a_hlht is neither 1 nor 2 code it to missing mutate(heightcm = ifelse(a_hlht == 1 &amp; a_hlhtf &gt; 0, a_hlhtf*30.48 + a_hlhti*2.54, ifelse(a_hlht == 2 &amp; a_hlhtc &gt; 0, a_hlhtc, NA))) %&gt;% # now same with weight mutate(weightkg = ifelse(a_hlwt == 1 &amp; a_hlwts &gt; 0, a_hlwts*6.35 + a_hlwtp*0.45, ifelse(a_hlwt == 2 &amp; a_hlwtk &gt; 0, a_hlwtk, NA))) %&gt;% # now create a variable for BMI mutate(bmi = weightkg / (heightcm / 100)^2) Let us now look at the distribution of BMI. hist(W1mod$bmi) 5.5 Sort data We can sort data with arrange. We may want to sort the data by BMI. W1mod %&gt;% arrange(bmi) %&gt;% select(pidp, bmi) %&gt;% head(5) ## # A tibble: 5 x 2 ## pidp bmi ## &lt;int&gt; &lt;dbl&gt; ## 1 614152207 3.581188 ## 2 1158204567 4.357708 ## 3 1292128539 10.098136 ## 4 1088805127 11.732290 ## 5 478722727 12.050592 We can also sort cases by BMI in the decreasing order, separatey for each sex. W1mod %&gt;% arrange(a_sex, desc(bmi)) %&gt;% select(pidp, a_sex, bmi) %&gt;% head(5) ## # A tibble: 5 x 3 ## pidp a_sex bmi ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 952435887 1 73.90269 ## 2 1632274047 1 66.37745 ## 3 340892847 1 65.19274 ## 4 1292157767 1 63.10072 ## 5 340443367 1 62.98222 5.6 Summarise data dplyr is also helpful when you want to create a data frame with summary statistics. For example, we may want to calculate mean and median BMI in our sample and the proportion of people with BMI over 30 (considered obese). W1mod %&gt;% # create a binary variable for being obese mutate(bmiover30 = ifelse(bmi &gt; 30, 1, 0)) %&gt;% summarise( meanBMI = mean(bmi, na.rm=TRUE), medianBMI = median(bmi, na.rm=TRUE), proportionObese = mean(bmiover30, na.rm=TRUE) ) ## # A tibble: 1 x 3 ## meanBMI medianBMI proportionObese ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 26.04229 25.37527 0.1807575 We can also produce summary statistics by group. Let us look at the BMI summaries by age group and by sex. W1mod %&gt;% # create a variabe for being obese mutate(bmiover30 = ifelse(bmi &gt; 30, 1, 0)) %&gt;% # create a variable for age groups mutate(agegr = ifelse(a_dvage &gt;= 18 &amp; a_dvage &lt;= 35, &quot;18-35&quot;, ifelse((a_dvage &gt;= 36 &amp; a_dvage &lt;= 55), &quot;36-55&quot;, ifelse(a_dvage &gt;= 56, &quot;&gt;55&quot;, NA)))) %&gt;% # filter out people with missing age filter(!is.na(agegr)) %&gt;% # group by sex and age group_by(a_sex, agegr) %&gt;% # calculate summary statistics summarise( meanBMI = mean(bmi, na.rm=TRUE), medianBMI = median(bmi, na.rm=TRUE), proportion = mean(bmiover30, na.rm=TRUE) ) ## # A tibble: 6 x 5 ## # Groups: a_sex [?] ## a_sex agegr meanBMI medianBMI proportion ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 &gt;55 26.95474 26.43255 0.1967436 ## 2 1 18-35 24.99670 24.46032 0.1179154 ## 3 1 36-55 27.25879 26.59878 0.2157322 ## 4 2 &gt;55 26.65251 25.96255 0.2168707 ## 5 2 18-35 24.48421 23.37306 0.1262995 ## 6 2 36-55 26.45840 25.38130 0.2179358 We can see that people aged 18 to 35 have the lowest proportion of obese people both among men and women. Let us now save W1mod for future use. saveRDS(W1mod, &quot;myData/W1mod.rds&quot;) "],
["joining.html", "6 Join data 6.1 Joining waves 1 and 2", " 6 Join data For this class please read ch.13 on Relational Data from R for Data Science – http://r4ds.had.co.nz/relational-data.html. 6.1 Joining waves 1 and 2 I will start with joining data from waves 1 and 2 and then expand the algorithm to all the seven waves. First we need to read the data into R. I am using the fundtion read_tsv() from the readr package here since the data are tab separated. # First I attach the packages I will use later. You need to install these packages first. library(tidyverse) library(data.table) library(reshape2) UndSoc1 &lt;- read_tsv(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;) UndSoc2 &lt;- read_tsv(&quot;data/UKDA-6614-tab/tab/us_w2/b_indresp.tab&quot;) These are very large files that take a lot of space in the memory. format(object.size(UndSoc1), units = &quot;auto&quot;) ## [1] &quot;273 Mb&quot; format(object.size(UndSoc2), units = &quot;auto&quot;) ## [1] &quot;350.6 Mb&quot; Before joining these two data frames I may want to select only the variables I need. These are: pidp: this is the unique cross-wave individual number (in both waves), a_sex: sex from wave 1, a_dvage: age from wave 1, a_vote6: level of interest in politics from wave 1, b_sex: sex from wave 2, b_dvage: age from wave 2, b_vote6: level of interest in politics from wave 2. Note that for now I keep it intentionally simple. First I will edit both data sets to keep only the variables I need. UndSoc1ed &lt;- UndSoc1 %&gt;% select(pidp, a_sex, a_dvage, a_vote6) UndSoc2ed &lt;- UndSoc2 %&gt;% select(pidp, b_sex, b_dvage, b_vote6) Note that these are much smaller objects. format(object.size(UndSoc1ed), units = &quot;auto&quot;) ## [1] &quot;1.3 Mb&quot; format(object.size(UndSoc2ed), units = &quot;auto&quot;) ## [1] &quot;5.5 Mb&quot; I will remove the larger data sets from the memory to free it up. rm(UndSoc1, UndSoc2) Let us explore the data. head(UndSoc1ed) ## # A tibble: 6 x 4 ## pidp a_sex a_dvage a_vote6 ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68001367 1 39 3 ## 2 68004087 1 59 2 ## 3 68006127 2 39 4 ## 4 68006135 2 17 4 ## 5 68006807 2 72 4 ## 6 68007487 2 57 1 head(UndSoc2ed) ## # A tibble: 6 x 4 ## pidp b_sex b_dvage b_vote6 ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68004087 1 60 2 ## 2 68006127 2 40 4 ## 3 68006807 2 73 4 ## 4 68007487 2 58 2 ## 5 68008167 2 39 4 ## 6 68008171 1 52 -7 Now we can join the data sets. As you know already, there can be several types of joins. Inner join will keep the observations that match in both data frames. inner &lt;- UndSoc1ed %&gt;% inner_join(UndSoc2ed, by = &quot;pidp&quot;) Note that I use the variable pidp as the key for joining. The same result can be achieved with the function merge from base R. inner2 &lt;- UndSoc1ed %&gt;% merge(UndSoc2ed, by = &quot;pidp&quot;) identical(as.data.frame(inner), inner2) ## [1] TRUE These two data frames are identical. Note the use of as.data.frame(). inner is a tibble and unless converted into a simple data frame it is not identical to inner2 because of the differences in object type. Inner join will only retain individuals that are present in both waves. This is why we only have 38388 observations in the joined data compared to 50994 in wave 1. But do we want this? Imagine that the person is present in wave 1, does not participate in wave 2, but then re-appears in wave 3. We probably want to include such individuals as well. Left join will keep all individuals in wave 1 and only those in wave 2 that can be matched to them. left &lt;- UndSoc1ed %&gt;% left_join(UndSoc2ed, by = &quot;pidp&quot;) # or, identically, # left &lt;- UndSoc1ed %&gt;% # merge(UndSoc2ed, by = &quot;pidp&quot;, all.x = TRUE) You can check that the number of individuals in wave 1 and the joined data frame is the same. Right join will keep all individuals from wave 2 and only those from wave 1 that can be matched to them. right &lt;- UndSoc1ed %&gt;% right_join(UndSoc2ed, by = &quot;pidp&quot;) # or, identically, # right &lt;- UndSoc1ed %&gt;% # merge(UndSoc2ed, by = &quot;pidp&quot;, all.y = TRUE) Usually I would want all the individuals from both waves to remain in the data set, no matter if they can be matched to other waves. If I need to exclude them from the analysis I prefer to do this manually. This can be achieved with full join. full &lt;- UndSoc1ed %&gt;% full_join(UndSoc2ed, by = &quot;pidp&quot;) # or, identically, # full &lt;- UndSoc1ed %&gt;% # merge(UndSoc2ed, by = &quot;pidp&quot;, all = TRUE) Note that full has 67203 observations compared to 50994 in wave 1 and 54597 in wave 2. This is because it includes a) all individuals that took part in both waves 1 and 2, b) those who took part in wave 1, but not in wave 2, c) those who missed wave 1 but joined the study in wave 2. Let us explore the joined data set. head(full) ## # A tibble: 6 x 7 ## pidp a_sex a_dvage a_vote6 b_sex b_dvage b_vote6 ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68001367 1 39 3 NA NA NA ## 2 68004087 1 59 2 1 60 2 ## 3 68006127 2 39 4 2 40 4 ## 4 68006135 2 17 4 NA NA NA ## 5 68006807 2 72 4 2 73 4 ## 6 68007487 2 57 1 2 58 2 We have missing values for wave 1 variable for those people who joined in wave 2. "],
["iteration.html", "7 Iteration", " 7 Iteration Please read ch.21 (Iteration) from R for Data Science - http://r4ds.had.co.nz/iteration.html In the Understanding Society data we have seven waves and seven separate individual files for adult questionnaires. We will need to read them all for the data to be joined. Of course, we can read them one by one, but this is inconvenient. We will use this example to learn about iteration, one of the most important concepts in programming. You should read ch.21 from R for Data Science and do the exercises to learn the basics; here we will consider how we can apply iteration to our case. Let us first consider a very simple for loop. for (i in 1:5) { print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 This loop goes through the values from 1 to 5 and in each iteration it prints the number on the screen. With the Understanding Society data, we want to go from 1 to 7 (as we have seven waves) and in each iteration we want to read in the data and join it to the data from other waves. Let us see how we can write a loop that does it. First, we need to identify the files we want to open. The dir function will return the paths and names of all the data files in our data folder that contain the pattern indresp. files &lt;- dir(&quot;data/UKDA-6614-tab/tab&quot;, pattern=&quot;indresp&quot;, recursive = TRUE, full.names=TRUE) files ## [1] &quot;data/UKDA-6614-tab/tab/bhps_w1/ba_indresp.tab&quot; ## [2] &quot;data/UKDA-6614-tab/tab/bhps_w10/bj_indresp.tab&quot; ## [3] &quot;data/UKDA-6614-tab/tab/bhps_w11/bk_indresp.tab&quot; ## [4] &quot;data/UKDA-6614-tab/tab/bhps_w12/bl_indresp.tab&quot; ## [5] &quot;data/UKDA-6614-tab/tab/bhps_w13/bm_indresp.tab&quot; ## [6] &quot;data/UKDA-6614-tab/tab/bhps_w14/bn_indresp.tab&quot; ## [7] &quot;data/UKDA-6614-tab/tab/bhps_w15/bo_indresp.tab&quot; ## [8] &quot;data/UKDA-6614-tab/tab/bhps_w16/bp_indresp.tab&quot; ## [9] &quot;data/UKDA-6614-tab/tab/bhps_w17/bq_indresp.tab&quot; ## [10] &quot;data/UKDA-6614-tab/tab/bhps_w18/br_indresp.tab&quot; ## [11] &quot;data/UKDA-6614-tab/tab/bhps_w2/bb_indresp.tab&quot; ## [12] &quot;data/UKDA-6614-tab/tab/bhps_w3/bc_indresp.tab&quot; ## [13] &quot;data/UKDA-6614-tab/tab/bhps_w4/bd_indresp.tab&quot; ## [14] &quot;data/UKDA-6614-tab/tab/bhps_w5/be_indresp.tab&quot; ## [15] &quot;data/UKDA-6614-tab/tab/bhps_w6/bf_indresp.tab&quot; ## [16] &quot;data/UKDA-6614-tab/tab/bhps_w7/bg_indresp.tab&quot; ## [17] &quot;data/UKDA-6614-tab/tab/bhps_w8/bh_indresp.tab&quot; ## [18] &quot;data/UKDA-6614-tab/tab/bhps_w9/bi_indresp.tab&quot; ## [19] &quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot; ## [20] &quot;data/UKDA-6614-tab/tab/us_w2/b_indresp.tab&quot; ## [21] &quot;data/UKDA-6614-tab/tab/us_w3/c_indresp.tab&quot; ## [22] &quot;data/UKDA-6614-tab/tab/us_w4/d_indresp.tab&quot; ## [23] &quot;data/UKDA-6614-tab/tab/us_w5/e_indresp.tab&quot; ## [24] &quot;data/UKDA-6614-tab/tab/us_w6/f_indresp.tab&quot; ## [25] &quot;data/UKDA-6614-tab/tab/us_w7/g_indresp.tab&quot; There are 25 files as we also have data from the BHPS, not just the Understanding Society. We do not need the BHPS, so we want to select only the files from the Understanding Society. We can use the function str_detect from the package stringr to select only the files whose paths contain us. # stringr will return a logical vector. Note that I specify which package the function comes from # without explicitly attaching it. stringr::str_detect(files, &quot;us&quot;) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [12] FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE ## [23] TRUE TRUE TRUE # Now I only select the files from UndSoc files &lt;- files[stringr::str_detect(files, &quot;us&quot;)] files ## [1] &quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot; ## [2] &quot;data/UKDA-6614-tab/tab/us_w2/b_indresp.tab&quot; ## [3] &quot;data/UKDA-6614-tab/tab/us_w3/c_indresp.tab&quot; ## [4] &quot;data/UKDA-6614-tab/tab/us_w4/d_indresp.tab&quot; ## [5] &quot;data/UKDA-6614-tab/tab/us_w5/e_indresp.tab&quot; ## [6] &quot;data/UKDA-6614-tab/tab/us_w6/f_indresp.tab&quot; ## [7] &quot;data/UKDA-6614-tab/tab/us_w7/g_indresp.tab&quot; Now we have a vector of file names we want to loop over. We can write a short loop that prints the path and files name. for (i in 1:7) { print(files[i]) } ## [1] &quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w2/b_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w3/c_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w4/d_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w5/e_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w6/f_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w7/g_indresp.tab&quot; Note that the same task can be achieved simply with: for (i in files) { print(i) } ## [1] &quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w2/b_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w3/c_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w4/d_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w5/e_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w6/f_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w7/g_indresp.tab&quot; You will see a bit later why I wanted to loop over numbers rather than elements of the character vector. Now we need to read in the data. We can read the whole files, but this is inefficient as we will only need a few variables. The function fread from the package data.table allows us to specify the variables we want to read. Let us choose the id variable (pidp), sex, age, interest in politics and net monthly income. The problem is that in each wave these variables have different names indicated by a prefix. pidp does not change and has the same name in each wave. All the other variables have a prefix a_ in wave 1, b_ in wave 2, etc. We will need to find a way to loop over not just file names in files, but also prefixes at the same time. Let us start with creating a vector of the variable names without the prefixes. vars &lt;- c(&quot;sex&quot;, &quot;dvage&quot;, &quot;vote6&quot;, &quot;fimnnet_dv&quot;) If we want to add a prefix to the elements of this vector we can use the function paste. paste(&quot;a&quot;, vars, sep = &quot;_&quot;) ## [1] &quot;a_sex&quot; &quot;a_dvage&quot; &quot;a_vote6&quot; &quot;a_fimnnet_dv&quot; The constant letters contains all the letters of the English alphabet, so the same expression can be written as the following. paste(letters[1], vars, sep = &quot;_&quot;) ## [1] &quot;a_sex&quot; &quot;a_dvage&quot; &quot;a_vote6&quot; &quot;a_fimnnet_dv&quot; Now we can write a loop that goes through the values 1 to 7 and in each iteration reads the correct data file choosing the variables with the correct prefix. # Attach data.table library(data.table) for (i in 1:7) { # Create a vector of the variables with the correct prefix. varsToSelect &lt;- paste(letters[i], vars, sep = &quot;_&quot;) # Add pidp to this vector (no prefix for pidp) varsToSelect &lt;- c(&quot;pidp&quot;, varsToSelect) # Now read the data. data &lt;- fread(files[i], select = varsToSelect) # print the first line print(head(data, 1)) } ## pidp a_sex a_dvage a_vote6 a_fimnnet_dv ## 1: 68001367 1 39 3 1400 ## pidp b_sex b_dvage b_vote6 b_fimnnet_dv ## 1: 68004087 1 60 2 1276.667 ## Read 40.2% of 49739 rows Read 49739 rows and 5 (of 3024) columns from 0.402 GB file in 00:00:04 ## pidp c_sex c_dvage c_vote6 c_fimnnet_dv ## 1: 68004087 1 61 2 914.3333 ## Read 84.8% of 47157 rows Read 47157 rows and 5 (of 2086) columns from 0.262 GB file in 00:00:03 ## pidp d_sex d_dvage d_vote6 d_fimnnet_dv ## 1: 68004087 1 62 1 914.3333 ## Read 66.8% of 44903 rows Read 44903 rows and 5 (of 2583) columns from 0.310 GB file in 00:00:03 ## pidp e_sex e_dvage e_vote6 e_fimnnet_dv ## 1: 68004087 1 63 2 1015.667 ## Read 88.3% of 45290 rows Read 45290 rows and 5 (of 2060) columns from 0.263 GB file in 00:00:03 ## pidp f_sex f_dvage f_vote6 f_fimnnet_dv ## 1: 68004087 1 64 2 1007.5 ## Read 47.4% of 42217 rows Read 42217 rows and 5 (of 2799) columns from 0.321 GB file in 00:00:03 ## pidp g_sex g_dvage g_vote6 g_fimnnet_dv ## 1: 68004087 1 65 2 1258.333 Now we need to join all these data frames together, and we want to do this in the loop. It is clear what we need to do in the second and later iterations of the loop: join the data from wave 2 with the data from wave 1, etc. But what shall we do in the first iteration? There is no data frame yet to be joined with the data from wave 1. Clearly our algorithm for the first iteration needs to be different from the algorithm for all other iterations. We will use the if … else control structure for this. In the first iteration of the loop we simply want to save the data from wave 1. In the second and other iterations we want the data to be joined with the data frame we have from the previous iteration. for (i in 1:7) { # Create a vector of the variables with the correct prefix. varsToSelect &lt;- paste(letters[i], vars, sep = &quot;_&quot;) # Add pidp to this vector (no prefix for pidp) varsToSelect &lt;- c(&quot;pidp&quot;, varsToSelect) # Now read the data. data &lt;- fread(files[i], select = varsToSelect) if (i == 1) { all7 &lt;- data } else { all7 &lt;- full_join(all7, data, by = &quot;pidp&quot;) } # Now we can remove data to free up memory rm(data) } ## Read 91.6% of 54597 rows Read 54597 rows and 5 (of 1615) columns from 0.233 GB file in 00:00:03 ## Read 40.2% of 49739 rows Read 49739 rows and 5 (of 3024) columns from 0.402 GB file in 00:00:04 ## Read 84.8% of 47157 rows Read 47157 rows and 5 (of 2086) columns from 0.262 GB file in 00:00:03 ## Read 66.8% of 44903 rows Read 44903 rows and 5 (of 2583) columns from 0.310 GB file in 00:00:03 ## Read 88.3% of 45290 rows Read 45290 rows and 5 (of 2060) columns from 0.263 GB file in 00:00:03 ## Read 71.1% of 42217 rows Read 42217 rows and 5 (of 2799) columns from 0.321 GB file in 00:00:03 all7 now contains the data from all seven waves. head(all7, 3) ## pidp a_sex a_dvage a_vote6 a_fimnnet_dv b_sex b_dvage b_vote6 ## 1 68001367 1 39 3 1400.0000 NA NA NA ## 2 68004087 1 59 2 802.0833 1 60 2 ## 3 68006127 2 39 4 1179.5267 2 40 4 ## b_fimnnet_dv c_sex c_dvage c_vote6 c_fimnnet_dv d_sex d_dvage d_vote6 ## 1 NA NA NA NA NA NA NA NA ## 2 1276.667 1 61 2 914.3333 1 62 1 ## 3 1115.993 2 41 4 1175.6666 2 43 4 ## d_fimnnet_dv e_sex e_dvage e_vote6 e_fimnnet_dv f_sex f_dvage f_vote6 ## 1 NA NA NA NA NA NA NA NA ## 2 914.3333 1 63 2 1015.667 1 64 2 ## 3 851.6666 2 43 4 1025.276 2 44 4 ## f_fimnnet_dv g_sex g_dvage g_vote6 g_fimnnet_dv ## 1 NA NA NA NA NA ## 2 1007.500 1 65 2 1258.333 ## 3 1108.833 2 45 4 385.000 I will now save this file for future use using the saveRDS function in the myData folder (make sure first you have this folder on your computer). saveRDS(all7, &quot;myData/all7.rds&quot;) "],
["tidy-data.html", "8 Tidy data 8.1 Long and wide formats 8.2 Cleaning the data", " 8 Tidy data For this class please read ch.12 on Tidy Data from R for Data Science – http://r4ds.had.co.nz/tidy-data.html. In the previous part of the course (joiningData.Rmd) we learned how to join together data from seven waves of the Understanding Society. Let us open this data set. UndSoc &lt;- readRDS(&quot;myData/all7.rds&quot;) head(UndSoc) ## pidp a_sex a_dvage a_vote6 a_fimnnet_dv b_sex b_dvage b_vote6 ## 1 68001367 1 39 3 1400.0000 NA NA NA ## 2 68004087 1 59 2 802.0833 1 60 2 ## 3 68006127 2 39 4 1179.5267 2 40 4 ## 4 68006135 2 17 4 130.0000 NA NA NA ## 5 68006807 2 72 4 933.8135 2 73 4 ## 6 68007487 2 57 1 400.0000 2 58 2 ## b_fimnnet_dv c_sex c_dvage c_vote6 c_fimnnet_dv d_sex d_dvage d_vote6 ## 1 NA NA NA NA NA NA NA NA ## 2 1276.66663 1 61 2 914.3333 1 62 1 ## 3 1115.99341 2 41 4 1175.6666 2 43 4 ## 4 NA 2 19 4 1100.0000 2 21 2 ## 5 1145.27893 2 74 4 1146.7035 2 75 4 ## 6 16.66666 2 59 4 475.0000 2 60 1 ## d_fimnnet_dv e_sex e_dvage e_vote6 e_fimnnet_dv f_sex f_dvage f_vote6 ## 1 NA NA NA NA NA NA NA NA ## 2 914.3333 1 63 2 1015.6667 1 64 2 ## 3 851.6666 2 43 4 1025.2756 2 44 4 ## 4 977.7525 2 21 4 823.0209 NA NA NA ## 5 1405.1293 2 76 4 15000.0000 2 77 4 ## 6 666.6168 NA NA NA NA NA NA NA ## f_fimnnet_dv g_sex g_dvage g_vote6 g_fimnnet_dv ## 1 NA NA NA NA NA ## 2 1007.500 1 65 2 1258.3334 ## 3 1108.833 2 45 4 385.0000 ## 4 NA 2 23 -7 909.2457 ## 5 904.209 2 78 3 996.6353 ## 6 NA NA NA NA NA Now we will work on how these data can be represented and prepared for the analysis. Please read ch.12 on Tidy Data from the R for Data Science Book – http://r4ds.had.co.nz/tidy-data.html. 8.1 Long and wide formats Let us keep only a few observations and columns in the data and more closely look at its structure. UndSocExample &lt;- UndSoc %&gt;% filter(pidp == 68001367 | pidp == 68004087) %&gt;% select(pidp, a_sex: b_fimnnet_dv) UndSocExample ## pidp a_sex a_dvage a_vote6 a_fimnnet_dv b_sex b_dvage b_vote6 ## 1 68001367 1 39 3 1400.0000 NA NA NA ## 2 68004087 1 59 2 802.0833 1 60 2 ## b_fimnnet_dv ## 1 NA ## 2 1276.667 These are the data for two individuals only in waves 1 and 2. The data are represented in the wide format. This means that we have one row for each individual, and data from different waves are recorded in several columns. For example, the data on sex from wave 1 is in column a_sex and the data on sex from wave is in b_sex. You will find this representation of the data common in longitudinal data sets. It may be convenient for certain purposes, but it is generally recommended to keep the data in the long format (that corresponds to the tidy data principles as described in the R for Data Science book). To move from the wide to the long format we can use the function melt and cast functions from the reshape2 package. require(reshape2) # First we &quot;melt&quot; the data frame. UndSocExampleMolten &lt;- UndSocExample %&gt;% melt(id = &quot;pidp&quot;) UndSocExampleMolten ## pidp variable value ## 1 68001367 a_sex 1.0000 ## 2 68004087 a_sex 1.0000 ## 3 68001367 a_dvage 39.0000 ## 4 68004087 a_dvage 59.0000 ## 5 68001367 a_vote6 3.0000 ## 6 68004087 a_vote6 2.0000 ## 7 68001367 a_fimnnet_dv 1400.0000 ## 8 68004087 a_fimnnet_dv 802.0833 ## 9 68001367 b_sex NA ## 10 68004087 b_sex 1.0000 ## 11 68001367 b_dvage NA ## 12 68004087 b_dvage 60.0000 ## 13 68001367 b_vote6 NA ## 14 68004087 b_vote6 2.0000 ## 15 68001367 b_fimnnet_dv NA ## 16 68004087 b_fimnnet_dv 1276.6666 # Next I want to split the column variable into a column indicating wave and a column indicating variable name. # I will use the function separate() from tidyr. UndSocExampleSep &lt;- UndSocExampleMolten %&gt;% separate(variable, into = c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;) UndSocExampleSep ## pidp wave variable value ## 1 68001367 a sex 1.0000 ## 2 68004087 a sex 1.0000 ## 3 68001367 a dvage 39.0000 ## 4 68004087 a dvage 59.0000 ## 5 68001367 a vote6 3.0000 ## 6 68004087 a vote6 2.0000 ## 7 68001367 a fimnnet 1400.0000 ## 8 68004087 a fimnnet 802.0833 ## 9 68001367 b sex NA ## 10 68004087 b sex 1.0000 ## 11 68001367 b dvage NA ## 12 68004087 b dvage 60.0000 ## 13 68001367 b vote6 NA ## 14 68004087 b vote6 2.0000 ## 15 68001367 b fimnnet NA ## 16 68004087 b fimnnet 1276.6666 # We have a problem here because one of our variables (fimnnet_dv) has _ in the name and we do not want to separate by it. To avoid this problem we need to add the argument extra = &quot;merge&quot;&quot; in separate(). UndSocExampleSep &lt;- UndSocExampleMolten %&gt;% separate(variable, into = c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;, extra = &quot;merge&quot;) UndSocExampleSep ## pidp wave variable value ## 1 68001367 a sex 1.0000 ## 2 68004087 a sex 1.0000 ## 3 68001367 a dvage 39.0000 ## 4 68004087 a dvage 59.0000 ## 5 68001367 a vote6 3.0000 ## 6 68004087 a vote6 2.0000 ## 7 68001367 a fimnnet_dv 1400.0000 ## 8 68004087 a fimnnet_dv 802.0833 ## 9 68001367 b sex NA ## 10 68004087 b sex 1.0000 ## 11 68001367 b dvage NA ## 12 68004087 b dvage 60.0000 ## 13 68001367 b vote6 NA ## 14 68004087 b vote6 2.0000 ## 15 68001367 b fimnnet_dv NA ## 16 68004087 b fimnnet_dv 1276.6666 # Next we &quot;cast&quot; the molten data frame into the format we want. UndSocExampleLong &lt;- UndSocExampleSep %&gt;% dcast(pidp + wave ~ variable) UndSocExampleLong ## pidp wave dvage fimnnet_dv sex vote6 ## 1 68001367 a 39 1400.0000 1 3 ## 2 68001367 b NA NA NA NA ## 3 68004087 a 59 802.0833 1 2 ## 4 68004087 b 60 1276.6666 1 2 Now the data are in the “long format”. This means that we have as many rows for each individual as the number of waves, a variable indicating wave, and all other variables are in columns. In most cases with longitudinal data, the long format is easier to work with. What if we want to convert the data back to the wide format? # First melt UndSocExampleMolten2 &lt;- UndSocExampleLong %&gt;% melt(id = c(&quot;pidp&quot;, &quot;wave&quot;)) UndSocExampleMolten2 ## pidp wave variable value ## 1 68001367 a dvage 39.0000 ## 2 68001367 b dvage NA ## 3 68004087 a dvage 59.0000 ## 4 68004087 b dvage 60.0000 ## 5 68001367 a fimnnet_dv 1400.0000 ## 6 68001367 b fimnnet_dv NA ## 7 68004087 a fimnnet_dv 802.0833 ## 8 68004087 b fimnnet_dv 1276.6666 ## 9 68001367 a sex 1.0000 ## 10 68001367 b sex NA ## 11 68004087 a sex 1.0000 ## 12 68004087 b sex 1.0000 ## 13 68001367 a vote6 3.0000 ## 14 68001367 b vote6 NA ## 15 68004087 a vote6 2.0000 ## 16 68004087 b vote6 2.0000 # Unite the columns UndSocExampleUnited &lt;- UndSocExampleMolten2 %&gt;% unite(&quot;variable&quot;, c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;) UndSocExampleUnited ## pidp variable value ## 1 68001367 a_dvage 39.0000 ## 2 68001367 b_dvage NA ## 3 68004087 a_dvage 59.0000 ## 4 68004087 b_dvage 60.0000 ## 5 68001367 a_fimnnet_dv 1400.0000 ## 6 68001367 b_fimnnet_dv NA ## 7 68004087 a_fimnnet_dv 802.0833 ## 8 68004087 b_fimnnet_dv 1276.6666 ## 9 68001367 a_sex 1.0000 ## 10 68001367 b_sex NA ## 11 68004087 a_sex 1.0000 ## 12 68004087 b_sex 1.0000 ## 13 68001367 a_vote6 3.0000 ## 14 68001367 b_vote6 NA ## 15 68004087 a_vote6 2.0000 ## 16 68004087 b_vote6 2.0000 # And now cast UndSocExampleWide &lt;- UndSocExampleUnited %&gt;% dcast(pidp ~ variable) UndSocExampleWide ## pidp a_dvage a_fimnnet_dv a_sex a_vote6 b_dvage b_fimnnet_dv b_sex ## 1 68001367 39 1400.0000 1 3 NA NA NA ## 2 68004087 59 802.0833 1 2 60 1276.667 1 ## b_vote6 ## 1 NA ## 2 2 We can also restructure the data using the gather and spread functions from the tidyr package (part of tidyverse). gather is roughy equivalent to melt and spread is roughy equivalent to dcast. Moving from wide to long: UndSocExample ## pidp a_sex a_dvage a_vote6 a_fimnnet_dv b_sex b_dvage b_vote6 ## 1 68001367 1 39 3 1400.0000 NA NA NA ## 2 68004087 1 59 2 802.0833 1 60 2 ## b_fimnnet_dv ## 1 NA ## 2 1276.667 # This &quot;melts&quot; the data frame. UndSocExample %&gt;% gather(a_sex:b_fimnnet_dv, key = &quot;variable&quot;, value = &quot;value&quot;) ## pidp variable value ## 1 68001367 a_sex 1.0000 ## 2 68004087 a_sex 1.0000 ## 3 68001367 a_dvage 39.0000 ## 4 68004087 a_dvage 59.0000 ## 5 68001367 a_vote6 3.0000 ## 6 68004087 a_vote6 2.0000 ## 7 68001367 a_fimnnet_dv 1400.0000 ## 8 68004087 a_fimnnet_dv 802.0833 ## 9 68001367 b_sex NA ## 10 68004087 b_sex 1.0000 ## 11 68001367 b_dvage NA ## 12 68004087 b_dvage 60.0000 ## 13 68001367 b_vote6 NA ## 14 68004087 b_vote6 2.0000 ## 15 68001367 b_fimnnet_dv NA ## 16 68004087 b_fimnnet_dv 1276.6666 # Next we want to split the &quot;variable&quot; column and &quot;cast&quot; in the long format UndSocExample %&gt;% gather(a_sex:b_vote6, key = &quot;variable&quot;, value = &quot;value&quot;) %&gt;% separate(variable, into = c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;, extra = &quot;merge&quot;) %&gt;% spread(key = variable, value = value) ## pidp b_fimnnet_dv wave dvage fimnnet_dv sex vote6 ## 1 68001367 NA a 39 1400.0000 1 3 ## 2 68001367 NA b NA NA NA NA ## 3 68004087 1276.667 a 59 802.0833 1 2 ## 4 68004087 1276.667 b 60 NA 1 2 If we want to move from long to wide: UndSocExampleLong ## pidp wave dvage fimnnet_dv sex vote6 ## 1 68001367 a 39 1400.0000 1 3 ## 2 68001367 b NA NA NA NA ## 3 68004087 a 59 802.0833 1 2 ## 4 68004087 b 60 1276.6666 1 2 UndSocExampleLong %&gt;% gather(dvage:vote6, key = &quot;variable&quot;, value = &quot;value&quot;) %&gt;% unite(&quot;variable&quot;, c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;) %&gt;% spread(key = variable, value = value) ## pidp a_dvage a_fimnnet_dv a_sex a_vote6 b_dvage b_fimnnet_dv b_sex ## 1 68001367 39 1400.0000 1 3 NA NA NA ## 2 68004087 59 802.0833 1 2 60 1276.667 1 ## b_vote6 ## 1 NA ## 2 2 Exercise. Reshape the full UndSoc data frame from wide to long format. Call the object where you will store the result UndSocLong. Solution: UndSocLong &lt;- UndSoc %&gt;% gather(a_sex:g_fimnnet_dv, key = &quot;variable&quot;, value = &quot;value&quot;) %&gt;% separate(variable, into = c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;, extra = &quot;merge&quot;) %&gt;% spread(key = variable, value = value) head(UndSocLong, 5) ## pidp wave dvage fimnnet_dv sex vote6 ## 1 22445 a NA NA NA NA ## 2 22445 b NA NA NA NA ## 3 22445 c NA NA NA NA ## 4 22445 d 27 1140.000 2 2 ## 5 22445 e 28 1602.667 2 2 8.2 Cleaning the data Before we begin the analysis we want to make sure that the data have been cleaned and all the missing values have been correctly identified. It usually makes sense to separate the cleaning and analysis stages into separate scripts. Let us explore the data set we have. Note that if we had not converted the data into the long format we would have to tabulate and clean each variable seven times. summary(UndSocLong) ## pidp wave dvage fimnnet_dv ## Min. :2.244e+04 Length:584703 Min. : -9.00 Min. :-42904 ## 1st Qu.:4.086e+08 Class :character 1st Qu.: 32.00 1st Qu.: 630 ## Median :7.493e+08 Mode :character Median : 46.00 Median : 1159 ## Mean :7.973e+08 Mean : 47.09 Mean : 1383 ## 3rd Qu.:1.224e+09 3rd Qu.: 61.00 3rd Qu.: 1800 ## Max. :1.653e+09 Max. :104.00 Max. : 15000 ## NA&#39;s :249806 NA&#39;s :249806 ## sex vote6 ## Min. :-9.00 Min. :-10.00 ## 1st Qu.: 1.00 1st Qu.: 2.00 ## Median : 2.00 Median : 3.00 ## Mean : 1.54 Mean : 1.82 ## 3rd Qu.: 2.00 3rd Qu.: 4.00 ## Max. : 2.00 Max. : 4.00 ## NA&#39;s :249806 NA&#39;s :249806 table(UndSocLong$wave) ## ## a b c d e f g ## 83529 83529 83529 83529 83529 83529 83529 table(UndSocLong$dvage) ## ## -9 -2 -1 16 17 18 19 20 21 22 23 24 25 26 27 ## 19 6 34 5735 5769 5536 5350 5188 5000 4779 4668 4537 4555 4556 4610 ## 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 ## 4742 4836 5129 5181 5286 5387 5380 5512 5591 5519 5765 5896 6155 6274 6422 ## 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 ## 6291 6450 6489 6316 6263 6187 6119 6013 5901 5727 5701 5483 5406 5193 5042 ## 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 ## 5052 4856 4782 4962 4995 5013 4999 4846 4814 4666 4435 4210 3914 3707 3504 ## 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 ## 3316 3130 2977 2749 2618 2452 2241 2106 1886 1749 1599 1390 1211 988 860 ## 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 ## 683 547 453 344 243 172 131 92 80 41 36 25 15 6 2 ## 103 104 ## 1 1 table(UndSocLong$sex) ## ## -9 -1 1 2 ## 2 1 154045 180849 table(UndSocLong$vote6) ## ## -10 -9 -7 -2 -1 1 2 3 4 ## 4656 366 24752 431 358 30981 102212 86790 84351 summary(UndSocLong$fimnnet_dv) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## -42904 630 1159 1383 1800 15000 249806 Note the negative values for dvage, sex and vote6. These are missing values that need to be coded as missing. UndSocLong &lt;- UndSocLong %&gt;% mutate(dvage = ifelse(dvage &gt; 0, dvage, NA)) %&gt;% mutate(sex = ifelse(sex &gt; 0, sex, NA)) %&gt;% mutate(vote6 = ifelse(vote6 &gt; 0, vote6, NA)) table(UndSocLong$dvage) ## ## 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ## 5735 5769 5536 5350 5188 5000 4779 4668 4537 4555 4556 4610 4742 4836 5129 ## 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 ## 5181 5286 5387 5380 5512 5591 5519 5765 5896 6155 6274 6422 6291 6450 6489 ## 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 ## 6316 6263 6187 6119 6013 5901 5727 5701 5483 5406 5193 5042 5052 4856 4782 ## 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 ## 4962 4995 5013 4999 4846 4814 4666 4435 4210 3914 3707 3504 3316 3130 2977 ## 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 ## 2749 2618 2452 2241 2106 1886 1749 1599 1390 1211 988 860 683 547 453 ## 91 92 93 94 95 96 97 98 99 100 101 102 103 104 ## 344 243 172 131 92 80 41 36 25 15 6 2 1 1 table(UndSocLong$sex) ## ## 1 2 ## 154045 180849 table(UndSocLong$vote6) ## ## 1 2 3 4 ## 30981 102212 86790 84351 We also have negative values for income (fimnnet_dv), but we will leave as it is for now. We may also want to code sex as “male” and “female” and assign meaningful labels to vote6 converting these variables into factors. UndSocLongClean &lt;- UndSocLong %&gt;% mutate(sex = recode(sex, &quot;1&quot; = &quot;male&quot;, &quot;2&quot; = &quot;female&quot;)) %&gt;% mutate(vote6 = recode(vote6, &quot;1&quot; = &quot;very&quot;, &quot;2&quot; = &quot;fairly&quot;, &quot;3&quot; = &quot;not very&quot;, &quot;4&quot; = &quot;not al all&quot;)) %&gt;% mutate(sex = factor(sex)) %&gt;% mutate(vote6 = factor(vote6)) head(UndSocLongClean, 10) ## pidp wave dvage fimnnet_dv sex vote6 ## 1 22445 a NA NA &lt;NA&gt; &lt;NA&gt; ## 2 22445 b NA NA &lt;NA&gt; &lt;NA&gt; ## 3 22445 c NA NA &lt;NA&gt; &lt;NA&gt; ## 4 22445 d 27 1140.000 female fairly ## 5 22445 e 28 1602.667 female fairly ## 6 22445 f 29 2012.000 female fairly ## 7 22445 g 30 1840.000 female very ## 8 29925 a NA NA &lt;NA&gt; &lt;NA&gt; ## 9 29925 b NA NA &lt;NA&gt; &lt;NA&gt; ## 10 29925 c NA NA &lt;NA&gt; &lt;NA&gt; saveRDS(UndSocLongClean, &quot;myData/all7clean.rds&quot;) "],
["datavis.html", "9 Data visualisation 9.1 Reading in the data 9.2 Visualising one quantitative variable 9.3 Visualising one categorical variable 9.4 Visualising two quantitative variables 9.5 Visualising one categorical and one quantitative variable 9.6 Visualising two categorical variables 9.7 Showing the relationships by group", " 9 Data visualisation Pre-requisite for this class: ch.3 (“Data visualisation”) from R for Data Science - http://r4ds.had.co.nz/data-visualisation.html At home you learned about the basic principles of data visualisation in R with the ggplot2 package. Let us see how we can apply this to the Understanding Society data set. Personally I can never remember all the details of the ggplot2 syntax. I often use the ready-made “recipes” from the R Graphics Cookbook by W.Chang – https://www.amazon.co.uk/R-Graphics-Cookbook-Winston-Chang/dp/1449316956/. The 2nd edition is coming out later this year – https://www.amazon.co.uk/Graphics-Cookbook-2e-Winston-Chang/dp/1491978600 . You may also find Winston Chang’s website useful (and not only for graphics) - http://www.cookbook-r.com . 9.1 Reading in the data First let us read in the data we used in week 2 when we learned about dplyr (a short version of the wave 1 data) and recreate the measures for weight, height and BMI. library(tidyverse) library(data.table) W1 &lt;- readRDS(&quot;myData/W1mod.rds&quot;) head(W1, 3) ## # A tibble: 3 x 15 ## pidp a_sex a_dvage a_ukborn a_hlht a_hlhtf a_hlhti a_hlhtc a_hlwt ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68001367 1 39 1 1 6 0 -8 1 ## 2 68004087 1 59 5 1 5 11 -8 2 ## 3 68006127 2 39 1 1 5 1 -8 1 ## # ... with 6 more variables: a_hlwts &lt;int&gt;, a_hlwtp &lt;int&gt;, a_hlwtk &lt;int&gt;, ## # heightcm &lt;dbl&gt;, weightkg &lt;dbl&gt;, bmi &lt;dbl&gt; 9.2 Visualising one quantitative variable Exercise. Visualise the distribution of the BMI with ggplot2. Which statistical graphs would be appropriate for this? 9.2.1 Histogram. ggplot(W1, aes(x=bmi)) + geom_histogram(bins = 100) + xlab(&quot;Body mass index&quot;) 9.2.2 Density chart. ggplot(W1, aes(x=bmi)) + geom_density() + xlab(&quot;Body mass index&quot;) 9.3 Visualising one categorical variable Exercise. Visualise the distribution of a_ukborn with ggplot2. Which statistical graphs would be appropriate for this? 9.3.1 Bar plot. table(W1$a_ukborn) ## ## -9 -2 -1 1 2 3 4 5 ## 6 2 8 33480 3567 2154 2033 9744 W1 &lt;- W1 %&gt;% mutate(a_ukborn = ifelse(a_ukborn &gt; 0, a_ukborn, NA)) %&gt;% mutate(cbirth = recode(a_ukborn, &quot;1&quot; = &quot;England&quot;, &quot;2&quot; = &quot;Scotland&quot;, &quot;3&quot; = &quot;Wales&quot;, &quot;4&quot; = &quot;Northern Ireland&quot;, &quot;5&quot; = &quot;Not UK&quot;)) table(W1$cbirth) ## ## England Northern Ireland Not UK Scotland ## 33480 2033 9744 3567 ## Wales ## 2154 W1 %&gt;% filter(!is.na(cbirth)) %&gt;% ggplot(aes(x=cbirth)) + geom_bar() + xlab(&quot;Country of birth&quot;) table(W1$cbirth, useNA = &quot;always&quot;) ## ## England Northern Ireland Not UK Scotland ## 33480 2033 9744 3567 ## Wales &lt;NA&gt; ## 2154 16 9.4 Visualising two quantitative variables Exercise. Visualise the joint distribution of weight (in kg) and height (in cm). In your chart show the regression line and the nonparametric smoothing line. ggplot(W1, aes(x = weightkg, y= heightcm)) + geom_point() + geom_smooth() + stat_smooth(method=lm) 9.5 Visualising one categorical and one quantitative variable Exercise. Visualise the distribution of BMI for a) men and women, b) different age groups. # Coding a categorical variable for age groups table(W1$a_dvage, useNA = &quot;always&quot;) ## ## 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ## 937 864 787 798 786 738 756 786 806 791 827 849 878 936 914 ## 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 ## 884 879 917 864 928 983 923 976 1051 1054 1032 1043 935 968 987 ## 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 ## 940 941 917 889 873 824 817 765 803 722 761 703 756 666 662 ## 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 ## 820 806 775 685 621 646 591 521 563 571 500 498 443 411 380 ## 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 ## 368 356 338 294 287 267 225 207 166 147 132 108 80 73 54 ## 91 92 93 94 95 96 97 98 99 100 101 &lt;NA&gt; ## 38 27 20 21 14 14 4 3 2 1 1 0 W1 &lt;- W1 %&gt;% mutate(agegr = ifelse(a_dvage &lt; 31, &quot;16-30&quot;, ifelse(a_dvage &gt; 30 &amp; a_dvage &lt; 46, &quot;31-45&quot;, ifelse(a_dvage &gt; 45 &amp; a_dvage &lt; 61, &quot;46-60&quot;, &quot;&gt;60&quot;)))) %&gt;% mutate(agegr = factor(agegr, c(&quot;16-30&quot;, &quot;31-45&quot;, &quot;46-60&quot;, &quot;&gt;60&quot;))) ggplot(W1, aes(x = agegr, y= bmi)) + geom_boxplot() + xlab(&quot;Age group&quot;) + ylab(&quot;Body mass index&quot;) 9.6 Visualising two categorical variables Exercise. Use facets to visualise the distribution of a_ukborn by age group. W1 %&gt;% filter(!is.na(cbirth)) %&gt;% ggplot(aes(x=cbirth)) + geom_bar() + xlab(&quot;Country of birth&quot;) + facet_wrap(~ agegr) Alternatively you can do a jitter plot, but in our case it wouldn’t look nice. W1 %&gt;% filter(!is.na(cbirth)) %&gt;% ggplot(aes(x=cbirth, y = agegr)) + geom_jitter() + xlab(&quot;Country of birth&quot;) + ylab(&quot;Age group&quot;) 9.7 Showing the relationships by group Exercise. Use facets to visualise the association between age and BMI by country of birth. W1 %&gt;% filter(!is.na(cbirth)) %&gt;% ggplot(aes(x = a_dvage, y= bmi)) + geom_point() + geom_smooth() + facet_wrap(~ cbirth) "],
["datavis2.html", "10 Data visualisation 2 10.1 Visualising income", " 10 Data visualisation 2 Pre-requisite for this class: ch.3 (“Data visualisation”) from R for Data Science - http://r4ds.had.co.nz/data-visualisation.html Also see the ggplot2 cheat sheet - https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf At the previous class we looked at some simple data visualisation techniques (see http://abessudnov.net/dataanalysis3/datavis.html). Now we will explore how we can visualise longitudinal data. First we want to read in the data frame we created when we learned to join and tidy data. UndSocLong &lt;- readRDS(&quot;myData/all7clean.rds&quot;) 10.1 Visualising income Now we want to visualise the distribution of income. There are several ways of doing this. First, we can create box plots for each wave. ggplot(UndSocLong, aes(x = wave, y= fimnnet_dv)) + geom_boxplot() + xlab(&quot;Wave&quot;) + ylab(&quot;Net monthly income&quot;) The chart does not look nice because of the outliers. We can either remove the outliers or display only a specified range of the box plots. ggplot(UndSocLong, aes(x = wave, y= fimnnet_dv)) + geom_boxplot() + xlab(&quot;Wave&quot;) + ylab(&quot;Net monthly income&quot;) + ylim(-500, 5000) We can see that the median income has been slowly increasing. Another way to display these data is a density plot. ggplot(UndSocLong, aes(x = fimnnet_dv)) + geom_density() + xlab(&quot;Net monthly income&quot;) + xlim(-500, 5000) We see a peak at zero incomes, and for positive incomes the distribution is close to normal. We can also create this chart for each wave separately. ggplot(UndSocLong, aes(x = fimnnet_dv)) + geom_density() + xlab(&quot;Net monthly income&quot;) + xlim(-500, 5000) + facet_wrap(~ wave) Now we may want to visualise the change of income across the waves. We can plot the income trajectories for each individual in the data set. Let us do this for the first five individuals. # 5 individuals, 7 waves: 5*7 = 35 first5 &lt;- UndSocLong %&gt;% slice(1:35) %&gt;% select(pidp, wave, fimnnet_dv) kable(first5) pidp wave fimnnet_dv 22445 a NA 22445 b NA 22445 c NA 22445 d 1140.000 22445 e 1602.667 22445 f 2012.000 22445 g 1840.000 29925 a NA 29925 b NA 29925 c NA 29925 d 0.000 29925 e NA 29925 f 2537.080 29925 g 2076.867 76165 a NA 76165 b NA 76165 c NA 76165 d NA 76165 e NA 76165 f NA 76165 g 1804.167 223725 a NA 223725 b NA 223725 c NA 223725 d NA 223725 e NA 223725 f NA 223725 g 3066.602 280165 a NA 280165 b 1183.872 280165 c 2367.884 280165 d 2828.061 280165 e 2324.167 280165 f 2335.695 280165 g 3049.700 ggplot(first5, aes(x = wave, y = fimnnet_dv, colour = as.factor(pidp))) + geom_point(na.rm = TRUE) + geom_line(aes(group = pidp), na.rm = TRUE) + ylab(&quot;Net monthly income&quot;) + xlab(&quot;Year&quot;) This chart nicely illustrates individual income trajectories, but if we try this for even 100 people the chart will be a complete mess. UndSocLong %&gt;% slice(1:700) %&gt;% ggplot(aes(x = wave, y = fimnnet_dv, group = pidp)) + geom_point(na.rm = TRUE) + geom_line(na.rm = TRUE) + ylab(&quot;Net monthly income&quot;) + xlab(&quot;Wave&quot;) Instead we can visualise summary statistics, such as mean or median. For a variable with outliers such as income median would be a better summary. # First we create a data frame of medians. medians &lt;- UndSocLong %&gt;% group_by(wave) %&gt;% summarise( medianIncome = median(fimnnet_dv, na.rm = TRUE) ) kable(medians) wave medianIncome a 1011.622 b 1087.900 c 1150.000 d 1183.333 e 1200.000 f 1231.594 g 1299.812 # Then visualize. # We need to add group = 1 because wave is not numeric ggplot(medians, aes(x = wave, y = medianIncome, group = 1)) + geom_point() + geom_line() + ylab(&quot;Median net monthly income&quot;) + xlab(&quot;Wave&quot;) There are a number of things we may want to do with this chart. First, we may want to change wave to year. Second, we may want to display confidence intervals for the point estimates. First, let us create a variable for year. We need to do this in the original data frame. For each wave in the Understanding Society, the data were collected for two years. So for Wave 1 the field work was conducted in 2009 and 2010. For simplicity, I will code the first year only. UndSocLong &lt;- UndSocLong %&gt;% mutate(year = recode(wave, &quot;a&quot; = &quot;2009&quot;, &quot;b&quot; = &quot;2010&quot;, &quot;c&quot; = &quot;2011&quot;, &quot;d&quot; = &quot;2012&quot;, &quot;e&quot; = &quot;2013&quot;, &quot;f&quot; = &quot;2014&quot;, &quot;g&quot; = &quot;2015&quot;)) %&gt;% mutate(year = as.numeric(year)) Producing confidence intervals for the median is not straightforward (you need to use statistical simulation or some other statistical tricks) so I’ll use the mean instead. UndSocLong %&gt;% group_by(year) %&gt;% summarise( # I use the function t.test to get the means and standard errors meanIncome = t.test(fimnnet_dv)$estimate, # Here I calculate the 95% confidence interval lowerIncome = t.test(fimnnet_dv)$conf.int[1], upperIncome = t.test(fimnnet_dv)$conf.int[2] ) %&gt;% # and now I visualise ggplot(aes(x = year, y = meanIncome)) + geom_point() + geom_line() + geom_ribbon(aes(ymin=lowerIncome, ymax=upperIncome), alpha=0.2) + ylab(&quot;Median net monthly income&quot;) + xlab(&quot;Year&quot;) The confidence intervals are quite wide. This is not surprising given our sample size. Another chart we can produce is not only for the medians (or means), but for different quantiles. Let us take the following quantiles: 0.01, 0.05, 0.1, 0.5. 0.9, 0.95, 0.99. This will show the change in income for the 1% poorest, 5% poorest, 10% poorest, etc. This can be done in several ways. If we use summarise to produce multiple quantiles it can get clumsy. UndSocLong %&gt;% group_by(year) %&gt;% summarise( quant1 = quantile(fimnnet_dv, 0.01, na.rm = TRUE), quant5 = quantile(fimnnet_dv, 0.05, na.rm = TRUE), quant10 = quantile(fimnnet_dv, 0.1, na.rm = TRUE), quant50 = quantile(fimnnet_dv, 0.5, na.rm = TRUE), quant90 = quantile(fimnnet_dv, 0.9, na.rm = TRUE), quant95 = quantile(fimnnet_dv, 0.95, na.rm = TRUE), quant99 = quantile(fimnnet_dv, 0.99, na.rm = TRUE) ) %&gt;% ungroup() %&gt;% # Now I need to convert this to a long format gather(quantile, value, quant1:quant99) %&gt;% # and plot ggplot(aes(x = year, y = value, colour = quantile)) + geom_point(na.rm = TRUE) + geom_line(na.rm = TRUE) + ylab(&quot;Net monthly income&quot;) + xlab(&quot;Year&quot;) A more economical way to write the code is the following. This time I will also select only people with positive net incomes. library(broom) UndSocLong %&gt;% filter(fimnnet_dv &gt; 0) %&gt;% nest(-year) %&gt;% mutate(Quantiles = map(data, ~ quantile(.$fimnnet_dv, c(0.01, 0.05, 0.1, 0.5, 0.9, 0.95, 0.99)))) %&gt;% unnest(map(Quantiles, tidy)) %&gt;% ggplot(aes(x = year, y = x, colour = names)) + geom_point(na.rm = TRUE) + geom_line(na.rm = TRUE) + ylab(&quot;Net monthly income&quot;) + xlab(&quot;Year&quot;) "],
["rmarkdown.html", "11 R Markdown", " 11 R Markdown For this class read ch.27 (“R Markdown”) from R for Data Science - http://r4ds.had.co.nz/r-markdown.html The traditional approach for statistical data analysis is to analyse the data and write up the results separately. For example, you may conduct your analysis in R and then copy the output to Word and write up your results there. This is an error prone approach. The code and the results are not synchronised so that if you change your code the results will not change automatically. You can also make mistakes when copying the results. R Markdown was designed to combine statistical analysis and communication into a single framework. The code and the results are combined in a single document, and you can also add text, external tables and images if you want. You can use R Markdown to produce documents in different formats (html, Word, pdf, presentation slides). This website has been produced using R Markdown. There are many places on the web where you can learn the basics of R Markdown and there is no point for me to repeat this here. Please see ch.27 from R for Data Science (http://r4ds.had.co.nz/r-markdown.html) and the official R Markdown website (https://rmarkdown.rstudio.com) and follow the links. You can also check this webpage: https://stat545.com/block007_first-use-rmarkdown.html (this is part of a course at the University of British Columbia that is similar to our module, but somewhat more advanced). Here I will focus on a few things that are specifically relevant for your reports. You can knit your reports in either pdf or Word formats. If you are going to use Word you will not be able to use the stargazer package for regression output. You may try to use a combination of the packages memisc and pander to achieve the same result (see https://stackoverflow.com/questions/24342162/regression-tables-in-markdown-format-for-flexible-use-in-r-markdown-v2), but I haven’t tried this and I cannot guarantee that it will work. Also see https://rmarkdown.rstudio.com/articles_docx.html If you want to knit as pdf you will need to install LaTeX first (https://www.latex-project.org). Install LaTeX (complete version), restart your computer, restart R Studio and it should all work automatically. If you knit as pdf with LaTeX stargazer will work just fine, but you need to set the results argument to ‘asis’ and run stargazer in a separate R chunk. The code will look something like ```{r results = 'asis'} stargazer(m1, m2, m3, m4, type = \"latex\") ``` You need to include all your code in your report. You do not need to include messages and warnings. You may also want to use cache to speed up rendering of your document. To achieve this result include in the beginning of your R Mardown file an R chunk setting the following global options. ```{r setup} knitr::opts_chunk$set(echo = TRUE) knitr::opts_chunk$set(message = FALSE) knitr::opts_chunk$set(warning = FALSE) knitr::opts_chunk$set(cache = TRUE) ``` If you experience problems with caching switch it to FALSE. To knit a document you can use a button in R Studio. In my experience, sometimes it does not work as intended. Then you can use the command line: rmarkdown::render(&quot;your_file.Rmd&quot;, &quot;rmarkdown::word_document&quot;) rmarkdown::render(&quot;your_file.Rmd&quot;, &quot;rmarkdown::pdf_document&quot;) You will want to include a bibliography in your report. An easy way to do this is simply to type it in the end of your document. However, this is not the most efficient way of doing this. I recommend you use Zotero for your bibliographies. You will also be able to use Zotero for essays for other modules and for your dissertation, even if you do not use R or R Markdown and write everything in Word. Once you master Zotero referencing and creating bibliographies will become much easier. Go to the Zotero website (https://www.zotero.org) and create an acount. Download and install the Zotero client for your computer (https://www.zotero.org/download/). Download and install a Zotero plugin for your web browser. Once you have done this you will be able to automatically save references to your Zotero libraries from Google Scholar and other sources. You can use Zotero with Word to reference and automatically create bibliographies. This is not relevant for this module, but for other modules and for your dissertation this is a very useful skill. To learn how to do this see https://www.zotero.org/support/word_processor_integration To use Zotero with R Markdown you need to do the following. Once you have added all the references to your library, export it as a bib file (File -&gt; Export Library -&gt; choose BibTex as the format). Save your bib file in the same folder as your R Markdown document. To learn how to reference and cite in R Markdown see https://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html To include a bibliography add the following line to the YAML header of your R Markdown document: bibliography: your_bibfile_name.bib The file example.Rmd available in the Github repo shows the minimal example of referencing and creating a bibliography with one source (see https://raw.githubusercontent.com/abessudnov/dataanalysis3/master/example.Rmd). The associated bib file is available here: https://raw.githubusercontent.com/abessudnov/dataanalysis3/master/example.bib. The bib file can be opened and edited in any text editor and you can also use special software to do this, such as JabRef (http://www.jabref.org). "],
["modelling.html", "12 Modelling 12.1 Cross-sectional analysis 12.2 Longitudinal analysis 12.3 Further reading", " 12 Modelling Pre-requisite for this class: ch.22-24 (“Model”) from R for Data Science - http://r4ds.had.co.nz/model-intro.html Let us explore how we can apply linear models with the Understanding Society data for your reports. First we need to read in the data. This is the same data frame that I used for Data visualisation 2. I saved it then so now I can simply open the file. library(tidyverse) UndSoc &lt;- readRDS(&quot;myData/all7clean.rds&quot;) We have a variable for interest in politics (vote6) and we will take it as the outcome variable we want to study. It is a discrete variable measured on a four-point scale (from “not at all interested” to “very interested”). It is an ordinal rather than continuous variable so strictly speaking it is not statisticaly appropriate to calculate the mean of this variable and to use simple linear regression. You will see though that we can still do this and learn something interesting from this exercise. First let us look at the distribution of the variable. table(UndSoc$vote6) ## ## fairly not al all not very very ## 102212 84351 86790 30981 To do the modelling we want to recode it to numeric. I will do this in such a way that larger values indicate stronger interest in politics. UndSoc &lt;- UndSoc %&gt;% mutate(polinterest = recode(vote6, &quot;very&quot; = &quot;4&quot;, &quot;fairly&quot; = &quot;3&quot;, &quot;not very&quot; = &quot;2&quot;, &quot;not al all&quot; = &quot;1&quot;)) %&gt;% mutate(polinterest = as.numeric(polinterest)) table(UndSoc$polinterest) ## ## 1 2 3 4 ## 102212 84351 86790 30981 12.1 Cross-sectional analysis Let us start from cross-sectional analysis, i.e. the analysis of the data at one point in time. You can choose any wave to do this; I will go with wave 1. First I create a separate data frame for wave 1 only. wave1 &lt;- UndSoc %&gt;% filter(wave == &quot;a&quot;) %&gt;% filter(!is.na(dvage)) 12.1.1 Age and political interest We will start with the association between age and political interest. It is always a good idea to start with visualisations. wave1 %&gt;% ggplot(aes(x = dvage, y = polinterest)) + geom_smooth() I fit a non-parametric smooth here with geom_smooth, and the association between age and political interest seems to be non-linear. We can also fit a regression line and see how well it describes the data. wave1 %&gt;% ggplot(aes(x = dvage, y = polinterest)) + geom_smooth() + geom_smooth(method = &quot;lm&quot;, colour = &quot;red&quot;) Up to the age of about 70 years two lines are pretty close and I’d say that the linear function adequately describes the data. However, for people older than 75 the linear assocition is inadequate and provides a really poor fit. 12.1.2 Sex and political interest Let us look at a bar chart showing the association between sex and political interest. wave1 %&gt;% ggplot(aes(x = sex, y = polinterest)) + geom_bar(stat = &quot;summary&quot;, fun.y = &quot;mean&quot;) We see that mean political interest is somewhat higher for men compared to women. 12.1.3 Linear model As I said above, the outcome variable is ordinal so fitting a linear model will have some limitations. For our purposes this is fine though. For your reports you should fit a linear model for ordered and binary outcomes. The linear model for binary outcomes is called the linear probability model. Please do not estimate logit or probit models for the purpose of this assignment. Of course, you cannot fit a linear model for nominal outcomes. If you outcome is nominal (this is unlikely), you should either stay with descriptive statistics and graphs or use a multinomial logit model. You should only do this if you are confident that you know what you are doing. Now we can fit a simple linear regression model with two predictors: age and sex. m1 &lt;- lm(polinterest ~ sex + dvage, wave1) summary(m1) ## ## Call: ## lm(formula = polinterest ~ sex + dvage, data = wave1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.1887 -1.1526 -0.1546 0.8444 1.8545 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.1599709 0.0131684 164.027 &lt; 2e-16 *** ## sexmale 0.0311712 0.0092932 3.354 0.000797 *** ## dvage -0.0001544 0.0002544 -0.607 0.543864 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.006 on 47527 degrees of freedom ## (3464 observations deleted due to missingness) ## Multiple R-squared: 0.0002434, Adjusted R-squared: 0.0002013 ## F-statistic: 5.785 on 2 and 47527 DF, p-value: 0.003074 Both age and sex are highly statistically significant predictors of political interest. Men on average are 0.3 points higher on the political interest scale. For age, a one-year difference is associated with about 0.01 change in political interest (older people are more interested). For two people with the age difference of about 30 years this corresponds to the difference in political interest of about 0.3. We have seen that the association between age and political interest is non-linear. To model this, we may want to include the quadratic term for age. m2 &lt;- lm(polinterest ~ sex + dvage + I(dvage^2), wave1) summary(m2) ## ## Call: ## lm(formula = polinterest ~ sex + dvage + I(dvage^2), data = wave1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.2622 -1.1460 -0.1550 0.8319 1.8626 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.250e+00 2.964e-02 75.927 &lt; 2e-16 *** ## sexmale 3.098e-02 9.292e-03 3.334 0.000858 *** ## dvage -4.491e-03 1.302e-03 -3.450 0.000561 *** ## I(dvage^2) 4.473e-05 1.317e-05 3.397 0.000682 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.006 on 47526 degrees of freedom ## (3464 observations deleted due to missingness) ## Multiple R-squared: 0.0004861, Adjusted R-squared: 0.000423 ## F-statistic: 7.704 on 3 and 47526 DF, p-value: 3.836e-05 The quadratic term is statistically significanty indicating a non-linear fit. Note, however, that the coefficients are now more difficult to interpret. We can visualise the association between age and political interest to get some idea of the effect size. wave1 %&gt;% ggplot(aes(x = dvage, y = polinterest)) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x + I(x^2)) Note that this visualisation does not control for sex. 12.1.4 Interaction effect between sex and age Another question we can ask is whether the association between age and political interest is the same or different for men and women. Note that in the previous model we control for sex, and the coefficient for age represents an averaged association between age and political interest for men and women. It is possible to have a situation where the association is very different for two sexes (for example, for men political interest increases with age and for women it decreases). To check this formally, we can fit a model with an interaction effect. m3 &lt;- lm(polinterest ~ sex * dvage, wave1) summary(m3) ## ## Call: ## lm(formula = polinterest ~ sex * dvage, data = wave1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.2063 -1.1515 -0.1598 0.8358 1.8779 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.1820665 0.0167967 129.911 &lt;2e-16 *** ## sexmale -0.0186997 0.0253038 -0.739 0.4599 ## dvage -0.0006375 0.0003416 -1.866 0.0620 . ## sexmale:dvage 0.0010844 0.0005118 2.119 0.0341 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.006 on 47526 degrees of freedom ## (3464 observations deleted due to missingness) ## Multiple R-squared: 0.0003378, Adjusted R-squared: 0.0002747 ## F-statistic: 5.354 on 3 and 47526 DF, p-value: 0.001103 We see that the interaction effect is indeed statistically significant and negative suggesting that for men the association between age and political interest is weaker. We can also fit a quadratic model. m4 &lt;- lm(polinterest ~ sex * dvage + sex * I(dvage^2), wave1) summary(m4) ## ## Call: ## lm(formula = polinterest ~ sex * dvage + sex * I(dvage^2), data = wave1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.3257 -1.1440 -0.1565 0.8364 1.8630 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.249e+00 3.931e-02 57.204 &lt;2e-16 *** ## sexmale 3.708e-02 5.910e-02 0.627 0.5304 ## dvage -3.836e-03 1.736e-03 -2.210 0.0271 * ## I(dvage^2) 3.288e-05 1.749e-05 1.879 0.0602 . ## sexmale:dvage -1.655e-03 2.624e-03 -0.631 0.5283 ## sexmale:I(dvage^2) 2.863e-05 2.657e-05 1.077 0.2813 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.006 on 47524 degrees of freedom ## (3464 observations deleted due to missingness) ## Multiple R-squared: 0.0006109, Adjusted R-squared: 0.0005058 ## F-statistic: 5.81 on 5 and 47524 DF, p-value: 2.273e-05 The interaction effect is highly statistically significant. To make sense of the association between age and political interest for men and women it is best to visualise this model. wave1 %&gt;% ggplot(aes(x = dvage, y = polinterest, colour = sex)) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x + I(x^2)) We can see that the lines for men and women are indeed different, although the non-linear pattern of the association is similar for both sexes. 12.1.5 Checking the assumptions In Data Analysis 2 your task was to check the assumptions underlying linear regression models. This is an important step, but it is less relevant for our work in this module. Many of these assumptions are about the distribution of residuals and affect standard errors of regression coefficients. This is very important for small samples, but less important for large samples like the one we have in the Understanding Society where standard errors are usually small compared to regression coefficients and moderate violation of the regression assumpions (such as not normal distribution of the residuals and heteroskedasticity) will not affect the results much. You do not have to show how you have checked the assumptions in your reports (although if you want to do it for yourself this would not hurt). Another common question is the interpretation of the R-squared coefficient. In Model 4 the R-squared coefficients was about 0.05 suggesting that age and sex can jointly account for about 5% of the variance of political interest. Is this an indication that the model is really poor? Yes, if your task is to build a model that predicts political interest well. This shows that just knowning a person’s age and sex you can only make a wild guess about their level of political interest (this isn’t really surprising). However, if our task is simply to explore the association between age, sex and political interest rather than to build a model that predicts political interest well, then we should not pay too much attention to R-squared. 12.1.6 Presenting the output for multiple regression models How to present the regression output in your reports? You can of course simply fo summary(m1) as we did above, but this does not look really nice. Another way is to use the package stargazer. Note that stargazer will only work if you knit your reports as pdf rather than Word. To knit as pdf you will need to install LaTeX on your computers (see https://www.latex-project.org). This is how the table produced by stargazer will look like. library(stargazer) stargazer(m1, m2, m3, m4, type = &quot;html&quot;) Dependent variable: polinterest (1) (2) (3) (4) sexmale 0.031*** 0.031*** -0.019 0.037 (0.009) (0.009) (0.025) (0.059) dvage -0.0002 -0.004*** -0.001* -0.004** (0.0003) (0.001) (0.0003) (0.002) I(dvage2) 0.00004*** 0.00003* (0.00001) (0.00002) sexmale:dvage 0.001** -0.002 (0.001) (0.003) sexmale:I(dvage2) 0.00003 (0.00003) Constant 2.160*** 2.250*** 2.182*** 2.249*** (0.013) (0.030) (0.017) (0.039) Observations 47,530 47,530 47,530 47,530 R2 0.0002 0.0005 0.0003 0.001 Adjusted R2 0.0002 0.0004 0.0003 0.001 Residual Std. Error 1.006 (df = 47527) 1.006 (df = 47526) 1.006 (df = 47526) 1.006 (df = 47524) F Statistic 5.785*** (df = 2; 47527) 7.704*** (df = 3; 47526) 5.354*** (df = 3; 47526) 5.810*** (df = 5; 47524) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 In your reports you will knit as LaTeX rather than html so you should do something like: ```{r results = 'asis'} stargazer(m1, m2, m3, m4, type = \"latex\") ``` The results argument shoud be set to asis so that the results are displayed correctly. Note that type is latex. stargazer has many options to customise the tables. Please do experiment with them. 12.2 Longitudinal analysis Now we may want to model how things change over time (i.e. do longitudinal modelling). 12.2.1 Simple model We will start from simply plotting mean political interest over time. # First let us code the variable for year. UndSoc &lt;- UndSoc %&gt;% mutate(year = dplyr::recode(wave, &quot;a&quot; = &quot;2009&quot;, &quot;b&quot; = &quot;2010&quot;, &quot;c&quot; = &quot;2011&quot;, &quot;d&quot; = &quot;2012&quot;, &quot;e&quot; = &quot;2013&quot;, &quot;f&quot; = &quot;2014&quot;, &quot;g&quot; = &quot;2015&quot;)) %&gt;% mutate(year = as.numeric(year)) UndSoc %&gt;% group_by(year) %&gt;% summarise( meanPI = mean(polinterest, na.rm = TRUE) ) %&gt;% ggplot(aes(x = year, y = meanPI)) + geom_point() + geom_line() The model that describes this chart will be the following. m5 &lt;- lm(polinterest ~ as.factor(year), UndSoc) summary(m5) ## ## Call: ## lm(formula = polinterest ~ as.factor(year), data = UndSoc) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.1679 -1.1410 -0.1499 0.8456 1.8659 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.166611 0.004598 471.239 &lt; 2e-16 *** ## as.factor(year)2010 -0.025622 0.006403 -4.002 6.29e-05 *** ## as.factor(year)2011 -0.032499 0.006567 -4.949 7.48e-07 *** ## as.factor(year)2012 -0.012206 0.006667 -1.831 0.0671 . ## as.factor(year)2013 -0.016678 0.006757 -2.468 0.0136 * ## as.factor(year)2014 -0.005982 0.006935 -0.862 0.3884 ## as.factor(year)2015 0.001248 0.006841 0.182 0.8552 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.002 on 304327 degrees of freedom ## (280369 observations deleted due to missingness) ## Multiple R-squared: 0.0001429, Adjusted R-squared: 0.0001231 ## F-statistic: 7.247 on 6 and 304327 DF, p-value: 9.377e-08 We can see from this model that in 2011 to 2013 political interest was statistically significantly lower than in 2009, and in 2015 it was statistically significantly higher. 12.2.2 Adding a time-constant variable We may want to check if the change in political interest depends on a time-constant variable such as sex. Was the change in mean political interest similar for men and women? UndSoc %&gt;% filter(!is.na(sex)) %&gt;% group_by(year, sex) %&gt;% summarise( meanPI = mean(polinterest, na.rm = TRUE) ) %&gt;% ggplot(aes(x = year, y = meanPI, colour = sex)) + geom_point() + geom_line() It does not look like there was an interaction between sex and year, but we can check it formally. m6 &lt;- lm(polinterest ~ as.factor(year)*sex, UndSoc) summary(m6) ## ## Call: ## lm(formula = polinterest ~ as.factor(year) * sex, data = UndSoc) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.1845 -1.1412 -0.1414 0.8471 1.8742 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.1529089 0.0061463 350.276 &lt; 2e-16 *** ## as.factor(year)2010 -0.0270956 0.0085615 -3.165 0.001552 ** ## as.factor(year)2011 -0.0243447 0.0087788 -2.773 0.005553 ** ## as.factor(year)2012 -0.0114615 0.0089222 -1.285 0.198930 ## as.factor(year)2013 -0.0176752 0.0090497 -1.953 0.050807 . ## as.factor(year)2014 -0.0056622 0.0092944 -0.609 0.542388 ## as.factor(year)2015 0.0016132 0.0091645 0.176 0.860277 ## sexmale 0.0311018 0.0092602 3.359 0.000783 *** ## as.factor(year)2010:sexmale 0.0032945 0.0128944 0.255 0.798338 ## as.factor(year)2011:sexmale -0.0185059 0.0132277 -1.399 0.161806 ## as.factor(year)2012:sexmale -0.0018507 0.0134231 -0.138 0.890341 ## as.factor(year)2013:sexmale 0.0019689 0.0136020 0.145 0.884911 ## as.factor(year)2014:sexmale -0.0009884 0.0139599 -0.071 0.943553 ## as.factor(year)2015:sexmale -0.0011004 0.0137721 -0.080 0.936317 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.002 on 304318 degrees of freedom ## (280371 observations deleted due to missingness) ## Multiple R-squared: 0.0003558, Adjusted R-squared: 0.0003131 ## F-statistic: 8.332 on 13 and 304318 DF, p-value: &lt; 2.2e-16 This suggest that the gap in political interest between men and women was slighty hgher in 2013, but the effect size is really small. 12.2.3 Adding a time-varying variable Things get more tricky (and more interesting) if we want to add a time-varying variable such as age to the analysis. We have already modelled the association between age and political interest cross-sectionally. This answers the question of whether there is any difference in political interest between people of different age. Another question that we may want to ask is whether political interest changes when people get older. Note that this is a different question, and answering it requires the use of longitudinal data. To answer this question we need to apply regression models with fixed effects. You have not covered these models in Data Analysis 2. The main idea is to look at the changes for the same individuals. We want to see if for each person in the data getting older is associated with the changes in political interest, and then we can average the effects across different people. In other words, instead of fitting the model that compares between individuals we want to compare within individuals. Technically, we can achieve this by simply controlling for individual id. With the data of our size the model will be very difficult to estimate, so for the demonstration purposes I will select 500 random individuals from the data and run the model for them. # creating a data frame with data for 500 random people set.seed(1) random500 &lt;- sample(unique(UndSoc$pidp), 500) UndSoc500 &lt;- UndSoc %&gt;% filter(pidp %in% random500) m7 &lt;- lm(polinterest ~ as.factor(year) + as.factor(pidp) + dvage, UndSoc500) If we run summary(m7) now we will get a really long output with 499 coefficients for pidp. I will use stargazer to present the results and will omit these coefficients (called individual fixed effects) and the coefficients for year. stargazer(m7, omit = c(&quot;pidp&quot;, &quot;year&quot;), type = &quot;html&quot;) Dependent variable: polinterest dvage -0.027 (0.112) Constant 4.767 (6.714) Observations 1,800 R2 0.460 Adjusted R2 0.271 Residual Std. Error 0.870 (df = 1333) F Statistic 2.438*** (df = 466; 1333) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 Note that the coefficient for age is not statisticaly significant. This indicates that as people get older their interest in politics does not change much, at least in our sub-sample of 500 people. A more efficient way to estimate fixed effects model is to use the package plm. library(plm) m8 &lt;- plm(polinterest ~ dvage, data = UndSoc500, model = &quot;within&quot;, index = c(&quot;pidp&quot;, &quot;year&quot;), effect = &quot;twoways&quot;) summary(m8) ## Twoways effects Within Model ## ## Call: ## plm(formula = polinterest ~ dvage, data = UndSoc500, effect = &quot;twoways&quot;, ## model = &quot;within&quot;, index = c(&quot;pidp&quot;, &quot;year&quot;)) ## ## Unbalanced Panel: n = 460, T = 1-7, N = 1800 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -2.55896 -0.38714 0.00000 0.40829 2.53312 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## dvage -0.027456 0.111871 -0.2454 0.8062 ## ## Total Sum of Squares: 1008.4 ## Residual Sum of Squares: 1008.4 ## R-Squared: 4.5185e-05 ## Adj. R-Squared: -0.34953 ## F-statistic: 0.0602342 on 1 and 1333 DF, p-value: 0.80616 Asking for the twoways effect means that we fit the model with individual and year fixed effects. Note that the effect size is exactly the same in models 7 and 8 (becuase this is essentially the same model), but plm will work faster. With plm you may be able to estimate the fixed effects model with the full data for your reports, although the estimation will take you some time. I will not do this here. 12.3 Further reading If you want to use linear models in your assignment I strongly recommend you consult the following book (available as an e-book in the library): J.Fox, S.Weisberg. (2011). An R Companion to Applied Regression. 2nd ed. Sage. The chapter on factors and interactions will be particularly useful. If you want to know more about fixed effects models see P.D.Allison. (2008). Fixed Effect Regression Models. Sage. To learn how to use the package plm read Y.Croissant, G.Millo. Panel Data Econometrics in R: The plm Package. https://cran.r-project.org/web/packages/plm/vignettes/plm.pdf "]
]
